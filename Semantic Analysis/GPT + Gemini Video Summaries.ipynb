{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16811,"status":"ok","timestamp":1723833035325,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"XKLbNNdRLR0T","outputId":"c71552d8-07d6-4fc0-c26b-83153e877f2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#Mount Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# 1.Extracting representative frames from video (10 equally spaced frames)."],"metadata":{"id":"oZ3QkTMbJGzk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5205,"status":"ok","timestamp":1726251432230,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"0p3fRJmJLcU3","outputId":"df77551c-e0f9-4b92-87b4-a163b8b3034a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n","Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n"]}],"source":["!pip install opencv-python ffmpeg-python\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2rvAmdjJMrhl"},"outputs":[],"source":["#Extract equally spaced video frames\n","\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","\n","def get_video_stats(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(f\"Error opening video {video_path}\")\n","        return None\n","\n","    # Get total frames and FPS\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    print(f\"Video Path: {video_path}\")\n","    print(f\"Total Frames: {total_frames}\")\n","    print(f\"FPS: {fps}\")\n","\n","    duration = total_frames / fps if fps > 0 else None\n","    if duration is None:\n","        print(\"FPS could not be retrieved.\")\n","\n","    cap.release()\n","    return duration\n","\n","def extract_frames(video_path, num_frames=10):\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n","    frames = []\n","    idx_set = set(frame_indices)\n","    current_idx = 0\n","    grabbed_frames = 0\n","\n","    while grabbed_frames < num_frames and cap.isOpened():\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            if current_idx in idx_set:\n","                frames.append(frame)\n","                grabbed_frames += 1\n","            current_idx += 1\n","\n","    cap.release()\n","    return frames, frame_indices\n","\n","def display_frames(frames):\n","    for i, frame in enumerate(frames):\n","        plt.figure(figsize=(10, 6))\n","        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","        plt.title(f'Frame {i+1}')\n","        plt.axis('off')\n","        plt.show()\n","\n","def save_frames(frames, video_path, frame_indices):\n","    base_name = os.path.splitext(os.path.basename(video_path))[0] #video basename\n","    output_dir = os.path.join('/content/drive/MyDrive/summaries/selected/', base_name)\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for i, frame in enumerate(frames):\n","        frame_index = frame_indices[i]\n","        frame_filename = os.path.join(output_dir, f\"{base_name}_frame_{frame_index}.png\")\n","        cv2.imwrite(frame_filename, frame)\n","        print(f\"Saved frame {i+1} to {frame_filename}\")\n","\n"]},{"cell_type":"code","source":["#From a folder of videos, pick random video under 10 minutes and extract frames.\n","\n","def walk_and_process_videos(root_folder):\n","    video_files = []\n","\n","    # Walk through the directory and collect all video files\n","    for dirpath, _, filenames in os.walk(root_folder):\n","        for filename in filenames:\n","            if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):\n","                video_files.append(os.path.join(dirpath, filename))\n","\n","    if not video_files:\n","        print(\"No video files found.\")\n","        return\n","\n","    random.shuffle(video_files)\n","\n","    for video_path in video_files:\n","        duration = get_video_stats(video_path)\n","        if duration is not None and duration < 600: #10 minute max\n","            print(f\"Processing {os.path.basename(video_path)} (Duration: {duration/60:.2f} minutes)\")\n","            frames, frame_indices = extract_frames(video_path)\n","            display_frames(frames)\n","\n","            # Ask the user if they want to save the frames\n","            save = input(\"Do you want to save these frames? (yes/no): \").strip().lower()\n","            if save == 'yes':\n","                save_frames(frames, video_path, frame_indices)\n","            break\n","    else:\n","        print(\"No video under 10 minutes was found.\")\n"],"metadata":{"id":"5WMhfQCJGjhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4821,"status":"ok","timestamp":1726252013264,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"sdR4xZAOWrOO","outputId":"6822b947-716f-41da-cb6b-497442565ec9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[  0  50 101 152 202 253 304 354 405 456]\n","Saved frame 1 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_0.png\n","Saved frame 2 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_50.png\n","Saved frame 3 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_101.png\n","Saved frame 4 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_152.png\n","Saved frame 5 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_202.png\n","Saved frame 6 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_253.png\n","Saved frame 7 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_304.png\n","Saved frame 8 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_354.png\n","Saved frame 9 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_405.png\n","Saved frame 10 to /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_456.png\n"]}],"source":["video_path = '/content/drive/MyDrive/summaries/selected/Incidents-00001040.MP4'\n","frames, frame_indices = extract_frames(video_path)\n","save_frames(frames, video_path, frame_indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1jQ_PAdGHFVmO50Pl8OmSsOnEWb-3z5Up"},"collapsed":true,"executionInfo":{"elapsed":19651,"status":"ok","timestamp":1725898241748,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"loJIHFPiNGCs","outputId":"506684c1-0536-416f-b8e5-106351b1e269"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["root_folder = '/content/drive/MyDrive/COPY'\n","\n","walk_and_process_videos(root_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5h6JOBnmIav"},"outputs":[],"source":["def check_if_video_processed(video_path):\n","    base_name = os.path.splitext(os.path.basename(video_path))[0]\n","    output_dir = os.path.join('/content/drive/MyDrive/summaries', base_name)\n","    return os.path.exists(output_dir)\n","\n","def walk_and_process_videos(root_folder, sample_size=100):\n","    video_files = []\n","\n","    for dirpath, _, filenames in os.walk(root_folder):\n","        for filename in filenames:\n","            if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):\n","                video_files.append(os.path.join(dirpath, filename))\n","\n","    if not video_files:\n","        print(\"No video files found.\")\n","        return\n","\n","    # Randomly shuffle list of video files\n","    random.shuffle(video_files)\n","\n","    selected_videos = []\n","    for video_path in video_files:\n","        if len(selected_videos) >= sample_size:\n","            break\n","        if check_if_video_processed(video_path):\n","            continue\n","\n","        duration = get_video_stats(video_path)\n","        if duration is not None and duration < 600:\n","            selected_videos.append(video_path)\n","\n","    if not selected_videos:\n","        print(\"No unprocessed videos under 10 minutes found.\")\n","        return\n","\n","    for video_path in selected_videos:\n","        print(f\"Processing {os.path.basename(video_path)} (Duration: {get_video_stats(video_path)/60:.2f} minutes)\")\n","        frames = extract_frames(video_path)\n","        #display_frames(frames)\n","        save_frames(frames, video_path)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"collapsed":true,"executionInfo":{"elapsed":164,"status":"error","timestamp":1749077952519,"user":{"displayName":"Karyn Nakamura","userId":"05408066286987856037"},"user_tz":240},"id":"7DGw_5YJErvc","outputId":"a257982f-0467-496c-e552-177d724ead0d"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'walk_and_process_videos' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4cb14f12cf93>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwalk_and_process_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/COPY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'walk_and_process_videos' is not defined"]}],"source":["walk_and_process_videos('/content/drive/MyDrive/COPY', sample_size=100)\n"]},{"cell_type":"markdown","source":["# 2. Passing frames to Gemini 1.5"],"metadata":{"id":"8p1_HPosJdHt"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13972,"status":"ok","timestamp":1727292148227,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"scIwv8UOlvFw","outputId":"54cc41d3-167f-4060-b8eb-5184c4c57557"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/153.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m143.4/153.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/760.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q -U google-generativeai\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-XHNbZLlyWX"},"outputs":[],"source":["import pathlib\n","import textwrap\n","\n","import google.generativeai as genai\n","\n","from IPython.display import display\n","from IPython.display import Markdown\n","\n","\n","def to_markdown(text):\n","  text = text.replace('•', '  *')\n","  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiKQrz8GlyRy"},"outputs":[],"source":["GOOGLE_API_KEY='key'#userdata.get('GOOGLE_API_KEY')\n","\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DlBnuqW9Okac"},"outputs":[],"source":["import os\n","from PIL import Image\n","\n","def create_ordered_images(frames_dir, limit=10):\n","    images = []\n","    for filename in os.listdir(frames_dir):\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            file_path = os.path.join(frames_dir, filename)\n","            try:\n","                img = Image.open(file_path)\n","                file_number = int(filename.split('_frame_')[1].split('.')[0])\n","                images.append((file_number, img))\n","                print(f\"Opened image {file_path} as img{file_number}\")\n","            except Exception as e:\n","                print(f\"Error opening image {file_path}: {e}\")\n","\n","    # Sort images by file_number\n","    images.sort(key=lambda x: x[0])\n","\n","    ordered_images = [img for _, img in images[:limit]]\n","\n","    return ordered_images\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5175,"status":"ok","timestamp":1727292225967,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"OiMdzXvGmdcX","outputId":"d228623d-5406-4b7a-a1b0-71ce6f348472"},"outputs":[{"output_type":"stream","name":"stdout","text":["Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_0.png as img0\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_50.png as img50\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_101.png as img101\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_152.png as img152\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_202.png as img202\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_253.png as img253\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_304.png as img304\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_354.png as img354\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_405.png as img405\n","Opened image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/Incidents-00001040_frame_456.png as img456\n"]}],"source":["frames_dir = '/content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040'\n","ordered_images = create_ordered_images(frames_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160},"executionInfo":{"elapsed":11015,"status":"ok","timestamp":1727292391421,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"o1hpjt_Jlsty","outputId":"3696ac13-0102-4ce9-c3d4-3cf3359fe60f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"> The images show a line of NYPD officers in riot gear facing a crowd of protesters. The officers are wearing black uniforms, helmets with visors, and face masks. They are carrying batons. The protesters are wearing a variety of clothing and some are also wearing face masks. One officer is wearing a badge that reads \"POLICE\" and has the number 17945 visible. The location appears to be a street in New York City, with streetlights and buildings visible in the background. The street signs visible say \"Bedford Ave\". There are several people holding up their phones and recording the confrontation. One sign in the background of the first image says \"Black Lives Matter\".  The officers are moving towards the crowd, while some protesters appear to be backing away. Some protesters are holding their hands up in the air. This sequence of images shows a tense encounter between the NYPD and protesters. \n"},"metadata":{},"execution_count":20}],"source":["#test\n","\n","model = genai.GenerativeModel('gemini-1.5-flash')\n","\n","response = model.generate_content([\"Describe this sequence of images of the NYPD at a protest and pay attention to the actions of people, any details on the location, identifying details like uniforms and badges, and any signs, numbers, and text in the images.\"] + ordered_images)\n","to_markdown(response.text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1727292355006,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"hBIFOFTKlsrH","outputId":"9447792e-8311-402c-8382-22e385a3f37e"},"outputs":[{"output_type":"stream","name":"stdout","text":["File saved at: /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/gemini_1_5_flash.txt\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040/gemini_1_5_flash.txt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["def save_string_to_file(text, folder_path, file_name):\n","    os.makedirs(folder_path, exist_ok=True)\n","    file_path = os.path.join(folder_path, file_name)\n","\n","    with open(file_path, 'w') as file:\n","        file.write(text)\n","\n","    print(f\"File saved at: {file_path}\")\n","    return file_path\n","\n","\n","folder_path = frames_dir #'/content/drive/MyDrive/summaries/selected/DEF_000321027/DEF_000321027_1987-2076'\n","file_name = 'gemini_1_5_flash.txt'\n","text_content = response.text\n","\n","save_string_to_file(text_content, folder_path, file_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGu1BQQ1wbSY"},"outputs":[],"source":["import os\n","import json\n","\n","def process_directory(base_dir, log_file='processed_folders.json', model_name='gemini-1.5-flash', output_file_name='gemini_1_5_flash.txt'):\n","    # Load the list of processed folders from the log file\n","    processed_folders = load_processed_folders(log_file)\n","    skip_folders = {'done', 'selected'}\n","\n","    for folder_name in os.listdir(base_dir):\n","        folder_path = os.path.join(base_dir, folder_name)\n","\n","        if os.path.isdir(folder_path) and folder_name not in skip_folders:\n","            if folder_name not in processed_folders:\n","                output_file_path = os.path.join(folder_path, output_file_name)\n","                if not os.path.exists(output_file_path):\n","                    try:\n","                        process_images_and_generate_summary(folder_path, model_name, output_file_name)\n","                        processed_folders.append(folder_name)\n","                        save_processed_folders(log_file, processed_folders)\n","                        print(f\"Processed and saved summary for folder: {folder_name}\")\n","                    except Exception as e:\n","                        print(f\"Error processing folder {folder_name}: {e}\")\n","                else:\n","                    print(f\"Summary already exists for folder: {folder_name}\")\n","            else:\n","                print(f\"Folder {folder_name} already processed.\")\n","\n","def process_images_and_generate_summary(frames_dir, model_name='gemini-1.5-flash', output_file_name='gemini_1_5_flash.txt'):\n","    os.makedirs(frames_dir, exist_ok=True)\n","    ordered_images = create_ordered_images(frames_dir)\n","    model = genai.GenerativeModel(model_name)\n","    response = model.generate_content(\n","        [\"Describe this sequence of images of from a video of the NYPD at a protest and pay attention to the actions of people, any details on the location, identifying details like uniforms and badges, and any signs, numbers, and text in the images.\"] + ordered_images\n","    )\n","    return save_string_to_file(response.text, frames_dir, output_file_name)\n","\n","def load_processed_folders(log_file):\n","\n","    if os.path.exists(log_file):\n","        with open(log_file, 'r') as file:\n","            return json.load(file)\n","    return []\n","\n","def save_processed_folders(log_file, processed_folders):\n","\n","    with open(log_file, 'w') as file:\n","        json.dump(processed_folders, file)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HWY_O3POxMDF","outputId":"363d82b1-83da-41d0-c726-45d5ceb560d2","collapsed":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_10.png as img10\n","Opened image /content/drive/MyDrive/summaries/Incidents-00000194/Incidents-00000194_frame_11.png as img11\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 21646.87ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00000194: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Summary already exists for folder: NYPD_N_00001085\n","Summary already exists for folder: MANDA_00000034\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_10.png as img10\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001862/Incidents-00001862_frame_11.png as img11\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 24302.07ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00001862: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002043/Incidents-00002043_frame_10.png as img10\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 24116.40ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00002043: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Summary already exists for folder: DEF_000320313\n","Summary already exists for folder: DEF_000514869\n","Summary already exists for folder: DEF_000322502\n","Summary already exists for folder: MANDA_00000143\n","Summary already exists for folder: DEF_000320178\n","Summary already exists for folder: DEF_000276544\n","Summary already exists for folder: MANDA_00000258\n","Summary already exists for folder: NYPD_N_00000619\n","Summary already exists for folder: DEF_000320733\n","Summary already exists for folder: NYPD_N_00000363\n","Summary already exists for folder: DEF_000322222\n","Summary already exists for folder: NYPD-0000096560\n","Summary already exists for folder: Incidents-00000891\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002091/Incidents-00002091_frame_10.png as img10\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 23139.75ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00002091: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Summary already exists for folder: MANDA_00000079\n","Summary already exists for folder: DEF_000320628\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Hearing-00000059/Hearing-00000059_frame_10.png as img10\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 20485.40ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Hearing-00000059: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001202/Incidents-00001202_frame_10.png as img10\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 25430.28ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00001202: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Summary already exists for folder: DEF_000322309\n","Summary already exists for folder: DEF_000514963\n","Summary already exists for folder: NYPD_N_00000511\n","Summary already exists for folder: DEF_000517431\n","Summary already exists for folder: DEF_000322239\n","Summary already exists for folder: DEF_000322486\n","Summary already exists for folder: Incidents-00000002\n","Summary already exists for folder: DEF_000320945\n","Summary already exists for folder: DEF_000321328\n","Summary already exists for folder: DEF_000270424\n","Summary already exists for folder: Payne-Ctrl-00000275\n","Summary already exists for folder: NYPD-0000102389\n","Summary already exists for folder: DEF_000321974\n","Summary already exists for folder: DEF_000276676\n","Summary already exists for folder: DEF_000270427\n","Summary already exists for folder: DEF_000320624\n","Summary already exists for folder: DEF_000517429\n","Summary already exists for folder: Incidents-00000039\n","Summary already exists for folder: DEF_000272058\n","Summary already exists for folder: DEF_000270326\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_10.png as img10\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002396/Incidents-00002396_frame_11.png as img11\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 24819.35ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00002396: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Summary already exists for folder: DEF_000277036\n","Summary already exists for folder: NYPD_N_00001263\n","Summary already exists for folder: DEF_000517426\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/DEFVID_000000149/DEFVID_000000149_frame_10.png as img10\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 32529.54ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder DEFVID_000000149: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Summary already exists for folder: DEF_000269465\n","Summary already exists for folder: DEF_000276714\n","Summary already exists for folder: DEF_000322574\n","Summary already exists for folder: DEF_000321295\n","Summary already exists for folder: Incidents-00001935\n","Summary already exists for folder: Incidents-00001691\n","Summary already exists for folder: DEF_000518651\n","Summary already exists for folder: DEF_000321278\n","Summary already exists for folder: DEF_000514911\n","Summary already exists for folder: NYPD-0000104490\n","Summary already exists for folder: DEF_000269568\n","Summary already exists for folder: DEF_000461448\n","Summary already exists for folder: Gut 3.mp4\n","Summary already exists for folder: DEF_000277078\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_10.png as img10\n","Opened image /content/drive/MyDrive/summaries/KHernandez-00000126/KHernandez-00000126_frame_11.png as img11\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 30070.25ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder KHernandez-00000126: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Summary already exists for folder: DEF_000277119\n","Summary already exists for folder: DEF_E_PD_00035902\n","Summary already exists for folder: DEF_000320695\n","Summary already exists for folder: NYPD_N_00001167\n","Summary already exists for folder: DEF_000514802\n","Summary already exists for folder: NYPD-0000113508\n","Summary already exists for folder: Incidents-00000583\n","Summary already exists for folder: NYPD_N_00000655\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_10.png as img10\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002038/Incidents-00002038_frame_11.png as img11\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 20608.34ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00002038: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_10.png as img10\n","Opened image /content/drive/MyDrive/summaries/Incidents-00002014/Incidents-00002014_frame_11.png as img11\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 22271.67ms\n"]},{"name":"stdout","output_type":"stream","text":["Error processing folder Incidents-00002014: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Request payload size exceeds the limit: 20971520 bytes.\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_1.png as img1\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_2.png as img2\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_3.png as img3\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_4.png as img4\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_5.png as img5\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_6.png as img6\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_7.png as img7\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_8.png as img8\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_9.png as img9\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_10.png as img10\n","Opened image /content/drive/MyDrive/summaries/Incidents-00001881/Incidents-00001881_frame_11.png as img11\n"]}],"source":["#Run on extracted frames dir\n","base_dir = '/content/drive/MyDrive/summaries'\n","process_directory(base_dir)"]},{"cell_type":"markdown","source":["# 3. Passing frames to ChatGPT"],"metadata":{"id":"VRhCS770J_jx"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4300,"status":"ok","timestamp":1726252265663,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"u9s2b8QRlsm4","outputId":"465a3116-7d99-4c79-d501-bce573987264"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n","Downloading openai-1.45.0-py3-none-any.whl (374 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.45.0\n"]}],"source":["!pip install openai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzMdmIzMpJ0n"},"outputs":[],"source":["import base64\n","import requests\n","\n","api_key = \"key\"\n","\n","def encode_image(image_path):\n","  with open(image_path, \"rb\") as image_file:\n","    return base64.b64encode(image_file.read()).decode('utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1726252274191,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"iAzQ-d5Jppy8","outputId":"d8b05b7c-76d0-4812-b776-d78b719f0ed5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_0.png as img0\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_50.png as img50\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_101.png as img101\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_152.png as img152\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_202.png as img202\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_253.png as img253\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_304.png as img304\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_354.png as img354\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_405.png as img405\n","Added image /content/drive/MyDrive/summaries/selected/Incidents-00001040/Incidents-00001040_frame_456.png as img456\n"]}],"source":["import os\n","image_folder = frames_dir#\"/content/drive/MyDrive/summaries/selected/DEF_000321027/DEF_000321027_1987-2076\"\n","limit = 10\n","sequence = []\n","\n","for filename in os.listdir(image_folder):\n","    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","        file_path = os.path.join(image_folder, filename)\n","        file_number = int(filename.split('_frame_')[1].split('.')[0])\n","        sequence.append((file_number, file_path))\n","        print(f\"Added image {file_path} as img{file_number}\")\n","sequence.sort(key=lambda x: x[0])\n","ordered_images = [file_path for _, file_path in sequence[:limit]]\n","\n","image_contents = []\n","\n","for image_path in ordered_images:\n","    base64_image = encode_image(image_path)\n","    image_contents.append(\n","        {\n","            \"type\": \"image_url\",\n","            \"image_url\": {\n","                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n","            }\n","        }\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1Oacxv9MLdsL35A8EShlK7UWpcDGIcIoS"},"id":"LwXkwW-zp1kO","outputId":"f8d0bc00-8b20-46fe-a5cd-a9d2fbb83a9c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {api_key}\"\n","}\n","\n","payload = {\n","    \"model\": \"gpt-4o-mini\",\n","    \"messages\": [\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": \"Describe this sequence of images of the NYPD at a protest and pay attention to the actions of people, any details on the location, identifying details like uniforms and badges, and any signs, numbers, and text in the images.\"\n","                }\n","            ] + image_contents\n","        }\n","    ],\n","    \"max_tokens\": 600\n","}\n","\n","print(payload)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aBfBXs5up40t","outputId":"515e80a8-e333-461f-f81d-fcf1e984d9ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["The sequence of images depicts a significant protest scene involving the NYPD. Here’s a detailed description based on the observed elements:\n","\n","1. **NYPD Presence**: Officers are prominently positioned in riot gear, wearing helmets with visors and uniforms indicating their affiliation with the NYPD. Notably, some officers have numbers displayed on their helmets (e.g., 17945, 22244).\n","\n","2. **Protesters**: Several individuals are visible in the foreground, many wearing masks. They exhibit expressions ranging from distress to agitation, suggesting a tense atmosphere. Some appear to be shielding their faces, possibly due to the presence of irritants like tear gas or other crowd control measures.\n","\n","3. **Actions and Reactions**: \n","   - In the early images, an officer is seen gesturing, possibly directing or communicating with the crowd. This hand signal may indicate an order or warning.\n","   - In subsequent images, groups of protesters appear to be fleeing or moving away from the police line, which indicates a response to escalating tensions.\n","\n","4. **Location Details**: \n","   - The backdrop features street signs (e.g., Bedford Ave) and illuminated traffic signals, suggesting an urban New York City setting during nighttime. A Shell gas station in one image adds to the urban context.\n","   - The lighting contributes to a tense and urgent atmosphere, with streetlights casting stark illumination on both protesters and officers.\n","\n","5. **Crowd Composition**: A diverse assembly of people is visible, with individuals ranging in age and appearance. They carry personal items such as phones, possibly recording or live-streaming the events.\n","\n","6. **Police Equipment**: The officers are equipped with batons and other crowd control tools. The visual presence of a police line indicates a structured response to the protest, which appears to be significant in scale.\n","\n","7. **Visual Chaos**: Empty plastic bottles and debris on the ground suggest prior confrontations or disturbances, adding to the chaotic nature of the scene.\n","\n","Overall, the sequence conveys a charged confrontation between the police and demonstrators amid a backdrop of urban familiarity, highlighting the complexities of public demonstrations in a metropolitan setting.\n"]}],"source":["#test\n","response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n","text = response.json()['choices'][0]['message']['content']\n","print(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1724955864655,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"},"user_tz":240},"id":"NGrqxo28ul3f","outputId":"2f12384d-1e9f-4f03-99aa-7e2f456128fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["File saved at: /content/drive/MyDrive/summaries/selected/DEF_000321027/DEF_000321027_8250-8685/gpt_4o_mini.txt\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/summaries/selected/DEF_000321027/DEF_000321027_8250-8685/gpt_4o_mini.txt'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","\n","def save_string_to_file(text, folder_path, file_name):\n","    os.makedirs(folder_path, exist_ok=True)\n","    file_path = os.path.join(folder_path, file_name)\n","    with open(file_path, 'w') as file:\n","        file.write(text)\n","\n","    print(f\"File saved at: {file_path}\")\n","    return file_path\n","\n","folder_path = frames_dir #'/content/drive/MyDrive/summaries/selected/DEF_000321027/DEF_000321027_1987-2076'\n","file_name = 'gpt_4o_mini.txt'\n","text_content = text\n","\n","save_string_to_file(text_content, folder_path, file_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwJggyNr1Pjb"},"outputs":[],"source":["import os\n","import requests\n","\n","def process_directory(base_dir, limit=10, model_name='gpt-4o-mini', output_file_name='gpt_4o_mini.txt', api_key=None):\n","\n","    skip_folders = {'done', 'selected'}\n","    for folder_name in os.listdir(base_dir) and folder_name not in skip_folders:\n","        folder_path = os.path.join(base_dir, folder_name)\n","        if os.path.isdir(folder_path):\n","            output_file_path = os.path.join(folder_path, output_file_name)\n","            if not os.path.exists(output_file_path):\n","                try:\n","                    sequence = []\n","\n","                    for filename in os.listdir(folder_path):\n","                        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","                            file_path = os.path.join(folder_path, filename)\n","                            file_number = int(filename.split('_frame_')[1].split('.')[0])\n","                            sequence.append((file_number, file_path))\n","                            print(f\"Added image {file_path} as img{file_number}\")\n","\n","                    sequence.sort(key=lambda x: x[0])\n","                    ordered_images = [file_path for _, file_path in sequence[:limit]]\n","\n","                    image_contents = []\n","\n","                    for image_path in ordered_images:\n","                        base64_image = encode_image(image_path)\n","                        image_contents.append(\n","                            {\n","                                \"type\": \"image_url\",\n","                                \"image_url\": {\n","                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n","                                }\n","                            }\n","                        )\n","\n","                    headers = {\n","                        \"Content-Type\": \"application/json\",\n","                        \"Authorization\": f\"Bearer {api_key}\"\n","                    }\n","\n","                    payload = {\n","                        \"model\": model_name,\n","                        \"messages\": [\n","                            {\n","                                \"role\": \"user\",\n","                                \"content\": [\n","                                    {\n","                                        \"type\": \"text\",\n","                                        \"text\": \"Describe this sequence of images of the NYPD at a protest and pay attention to the actions of people, any details on the location, identifying details like uniforms and badges, and any signs, numbers, and text in the images.\"\n","                                    }\n","                                ] + image_contents\n","                            }\n","                        ],\n","                        \"max_tokens\": 600\n","                    }\n","\n","                    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n","                    text = response.json()['choices'][0]['message']['content']\n","                    print(text)\n","\n","                    save_string_to_file(text, folder_path, output_file_name)\n","\n","                except Exception as e:\n","                    print(f\"Error processing folder {folder_name}: {e}\")\n","            else:\n","                print(f\"Summary already exists for folder: {folder_name}\")\n","\n","def save_string_to_file(text, folder_path, file_name):\n","    os.makedirs(folder_path, exist_ok=True)\n","    file_path = os.path.join(folder_path, file_name)\n","    with open(file_path, 'w') as file:\n","        file.write(text)\n","\n","    print(f\"File saved at: {file_path}\")\n","    return file_path\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffk96CiB127T"},"outputs":[],"source":["#Run on extracted frames dir\n","base_dir = '/content/drive/MyDrive/summaries'\n","api_key = \"key\"\n","\n","process_directory(base_dir, api_key=api_key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6AykXumwIh6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lgjm-Rne2Buo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9_y825ewFcQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRExohZ8wFZd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmojLUWawFVz"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}