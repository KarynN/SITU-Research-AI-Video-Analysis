{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-EUjvLLrPjg","executionInfo":{"status":"ok","timestamp":1717439606510,"user_tz":240,"elapsed":22498,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"7b058f78-056e-45da-9e80-680b83f26c84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#!pip install --upgrade scenedetect[opencv]\n","#!pip install opencv-python --upgrade\n","!apt-get install -y ffmpeg\n","\n","\n","!pip install llama-index\n","!pip install llama-index-llms-huggingface\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EAJcnL3Yryxb","executionInfo":{"status":"ok","timestamp":1717439724290,"user_tz":240,"elapsed":108704,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"afa65679-c035-46c6-f197-fdb96040b890"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","Collecting llama-index\n","  Downloading llama_index-0.10.43-py3-none-any.whl (6.8 kB)\n","Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n","Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n","Collecting llama-index-core==0.10.43 (from llama-index)\n","  Downloading llama_index_core-0.10.43-py3-none-any.whl (15.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n","  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n","Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n","Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n","  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n","  Downloading llama_index_llms_openai-0.1.22-py3-none-any.whl (11 kB)\n","Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n","Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n","Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n","Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (6.0.1)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (3.9.5)\n","Collecting dataclasses-json (from llama-index-core==0.10.43->llama-index)\n","  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.43->llama-index)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.43->llama-index)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2023.6.0)\n","Collecting httpx (from llama-index-core==0.10.43->llama-index)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core==0.10.43->llama-index)\n","  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.25.2)\n","Collecting openai>=1.1.0 (from llama-index-core==0.10.43->llama-index)\n","  Downloading openai-1.30.5-py3-none-any.whl (320 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (9.4.0)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (8.3.0)\n","Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.43->llama-index)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (4.12.0)\n","Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.43->llama-index)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index) (1.14.1)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n","Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n","  Downloading llama_parse-0.4.4-py3-none-any.whl (8.0 kB)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index) (4.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n","Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama-index) (2.7.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (2024.2.2)\n","Collecting httpcore==1.* (from httpx->llama-index-core==0.10.43->llama-index)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.43->llama-index) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.43->llama-index)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index) (2024.5.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.43->llama-index) (1.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.43->llama-index) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.43->llama-index) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.43->llama-index) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.43->llama-index)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.43->llama-index)\n","  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama-index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama-index) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.43->llama-index) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.43->llama-index) (1.2.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.43->llama-index) (24.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama-index) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama-index) (2.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.43->llama-index) (1.16.0)\n","Installing collected packages: striprtf, dirtyjson, pypdf, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n","Successfully installed dataclasses-json-0.6.6 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-0.10.43 llama-index-agent-openai-0.2.7 llama-index-cli-0.1.12 llama-index-core-0.10.43 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.22 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.23 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.4 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.30.5 pypdf-4.2.0 striprtf-0.0.26 tiktoken-0.7.0 typing-inspect-0.9.0\n","Collecting llama-index-llms-huggingface\n","  Downloading llama_index_llms_huggingface-0.2.3-py3-none-any.whl (10 kB)\n","Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.23.2)\n","Requirement already satisfied: llama-index-core<0.11.0,>=0.10.41 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (0.10.43)\n","Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n","  Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (2.3.0+cu121)\n","Requirement already satisfied: transformers[torch]<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-huggingface) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.0)\n","Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.9.5)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.6.6)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.8)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.27.0)\n","Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.1.19)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.3)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.25.2)\n","Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.30.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.0.3)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (9.4.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.3.0)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.7.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.14.1)\n","Requirement already satisfied: pydantic<3,>2 in /usr/local/lib/python3.10/dist-packages (from text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.7.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.3)\n","Collecting accelerate>=0.21.0 (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface)\n","  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (4.0.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (0.14.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.4.2)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.7.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>2->text-generation<0.8.0,>=0.7.0->llama-index-llms-huggingface) (2.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (3.21.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (2024.1)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.41->llama-index-llms-huggingface) (1.16.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, text-generation, nvidia-cusolver-cu12, accelerate, llama-index-llms-huggingface\n","Successfully installed accelerate-0.30.1 llama-index-llms-huggingface-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 text-generation-0.7.0\n"]}]},{"cell_type":"code","source":["import subprocess\n","import json\n","\n","# Path to your video file\n","videopath = \"/content/drive/MyDrive/COPY/VOL00002/NATIVES/NATIVE00001/DEF_000268134.mp4\"\n","\n","# Run FFmpeg to get metadata\n","result = subprocess.run(['ffmpeg', '-i', videopath, '-f', 'ffmetadata', '-'], capture_output=True, text=True)\n","\n","# Parse the metadata output\n","metadata_output = result.stderr\n","#print(metadata_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pf8ThBc3abK4","executionInfo":{"status":"ok","timestamp":1717449121236,"user_tz":240,"elapsed":744,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"1aebda6b-397c-4ede-ed7a-3f0dd2cfb1c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/COPY/VOL00002/NATIVES/NATIVE00001/DEF_000268134.mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp42mp41iso4\n","    creation_time   : 2020-06-03T02:12:09.000000Z\n","  Duration: 00:00:28.79, start: 0.000000, bitrate: 2326 kb/s\n","  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720, 2194 kb/s, 30.02 fps, 30 tbr, 600 tbn, 60 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-06-03T02:12:09.000000Z\n","      handler_name    : Vireo Eyes v2.5.3\n","      vendor_id       : [0][0][0][0]\n","      encoder         : AVC Coding\n","  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 128 kb/s (default)\n","    Metadata:\n","      creation_time   : 2020-06-03T02:12:09.000000Z\n","      handler_name    : Vireo Ears v2.5.3\n","      vendor_id       : [0][0][0][0]\n","Output #0, ffmetadata, to 'pipe:':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp42mp41iso4\n","    encoder         : Lavf58.76.100\n","Stream mapping:\n","Press [q] to stop, [?] for help\n","size=       0kB time=-577014:32:22.77 bitrate=N/A speed=N/A    \n","video:0kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n","Output file is empty, nothing was encoded \n","\n"]}]},{"cell_type":"code","source":["# Path to your video file\n","videopath = \"/content/drive/MyDrive/Test video/pexels_videos_2583475 (1080p).mp4\"\n","\n","# Run FFmpeg to get metadata\n","result = subprocess.run(['ffmpeg', '-i', videopath, '-f', 'ffmetadata', '-'], capture_output=True, text=True)\n","\n","# Parse the metadata output\n","metadata_output2 = result.stderr\n","print(metadata_output2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YbUndQV9qP7t","executionInfo":{"status":"ok","timestamp":1717444436598,"user_tz":240,"elapsed":680,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"fbeb30e6-f3e4-4357-e9db-a03cba930b31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/Test video/pexels_videos_2583475 (1080p).mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp42mp41isomavc1\n","    creation_time   : 2019-06-29T15:34:43.000000Z\n","  Duration: 00:00:15.27, start: 0.000000, bitrate: 5178 kb/s\n","  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1920x1080, 5036 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 48k tbc (default)\n","    Metadata:\n","      creation_time   : 2019-06-29T15:34:43.000000Z\n","      handler_name    : L-SMASH Video Handler\n","      vendor_id       : [0][0][0][0]\n","      encoder         : AVC Coding\n","  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 137 kb/s (default)\n","    Metadata:\n","      creation_time   : 2019-06-29T15:34:43.000000Z\n","      handler_name    : L-SMASH Audio Handler\n","      vendor_id       : [0][0][0][0]\n","Output #0, ffmetadata, to 'pipe:':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp42mp41isomavc1\n","    encoder         : Lavf58.76.100\n","Stream mapping:\n","Press [q] to stop, [?] for help\n","size=       0kB time=-577014:32:22.77 bitrate=N/A speed=N/A    \n","video:0kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n","Output file is empty, nothing was encoded \n","\n"]}]},{"cell_type":"code","source":["import os\n","import openai\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"key\"\n"],"metadata":{"id":"pO3AI2OWdRZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import Document\n","\n","documents = Document(text=metadata_output)"],"metadata":{"id":"CwsZID7VenbL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import Document\n","from llama_index.core.schema import MetadataMode\n","\n","document = Document(\n","    text=metadata_output,\n","    metadata={\n","        \"file_name\": \"DEF_000260727.mp4\",\n","    },\n","    excluded_llm_metadata_keys=[\"file_name\"],\n","    metadata_seperator=\"::\",\n","    metadata_template=\"{key}=>{value}\",\n","    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",")\n","\n","print(\n","    \"The LLM sees this: \\n\",\n","    document.get_content(metadata_mode=MetadataMode.LLM),\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_b1VgJrgzIh","executionInfo":{"status":"ok","timestamp":1717442013104,"user_tz":240,"elapsed":106,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"621f92f2-dd71-4237-cdbc-36659491923b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The LLM sees this: \n"," ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/Test video/DEF_000260727.mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp42mp41iso4\n","    creation_time   : 2020-06-01T02:52:01.000000Z\n","  Duration: 00:00:33.32, start: 0.000000, bitrate: 2386 kb/s\n","  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720, 2253 kb/s, 29.98 fps, 30 tbr, 600 tbn, 60 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-06-01T02:52:01.000000Z\n","      handler_name    : Vireo Eyes v2.5.3\n","      vendor_id       : [0][0][0][0]\n","      encoder         : AVC Coding\n","  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n","    Metadata:\n","      creation_time   : 2020-06-01T02:52:01.000000Z\n","      handler_name    : Vireo Ears v2.5.3\n","      vendor_id       : [0][0][0][0]\n","Output #0, ffmetadata, to 'pipe:':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp42mp41iso4\n","    encoder         : Lavf58.76.100\n","Stream mapping:\n","Press [q] to stop, [?] for help\n","size=       0kB time=-577014:32:22.77 bitrate=N/A speed=N/A    \n","video:0kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n","Output file is empty, nothing was encoded \n","\n"]}]},{"cell_type":"code","source":["from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n","\n","node1 = TextNode(text=metadata_output)\n","node2 = TextNode(text=metadata_output)\n","# set relationships\n","node1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n","    node_id=node2.node_id\n",")\n","node2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n","    node_id=node1.node_id\n",")\n","nodes = [node1, node2]"],"metadata":{"id":"EXNKP9sVinRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core import VectorStoreIndex\n","\n","vector_index = VectorStoreIndex(nodes)\n"],"metadata":{"id":"CfwCS1eve9pF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query_engine = vector_index.as_query_engine()\n","response = query_engine.query(\"what are all details related to time?\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GSrI9ThjFCg","executionInfo":{"status":"ok","timestamp":1717442556121,"user_tz":240,"elapsed":2875,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"5573b803-7a52-4f8e-c017-f481db93bd93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The input video has a duration of 00:00:33.32, starting at 0.000000 seconds with a bitrate of 2386 kb/s. The video stream has a frame rate of 29.98 frames per second, a time base of 30 tbr, 600 tbn, and 60 tbc. The creation time of the video is 2020-06-01T02:52:01.000000Z.\n"]}]},{"cell_type":"code","source":["from llama_index.core import Document\n","\n","text_list = [\"DEF_000260727.mp4\",\"pexels_videos_2583475 (1080p).mp4\"]\n","metadata_list = [metadata_output, metadata_output2]\n","\n","data_dict = dict(zip(text_list, metadata_list))\n","\n","\n","documents = [Document(text=t) for t in text_list]\n","\n","\n","\n"],"metadata":{"id":"Q-hN10M9jmj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_index = VectorStoreIndex.from_documents(documents)\n","vector_index.as_query_engine()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8JYz2bfjmgo","executionInfo":{"status":"ok","timestamp":1717445731612,"user_tz":240,"elapsed":422,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"a4156a4b-9abe-4efe-cb53-76c3d079d462"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x793286055180>"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["response = query_engine.query(\"what are all details related to time?\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRmA6rvWjmeQ","executionInfo":{"status":"ok","timestamp":1717445762287,"user_tz":240,"elapsed":2585,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"dc08565a-20f0-443a-aed0-e5c49dca3c40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The video has a duration of 00:00:33.32, starting at 0.000000 seconds. The video has a bitrate of 2386 kb/s. The video stream has a frame rate of 29.98 frames per second, with a time base of 30 tbr, 600 tbn, and 60 tbc. The audio stream has a sample rate of 44100 Hz.\n"]}]},{"cell_type":"code","source":["data_dict = {}\n","\n","import sqlite3\n","\n","# Connect to the database file\n","conn = sqlite3.connect('/content/drive/MyDrive/Databases/ffmpegmetadata.db')\n","\n","# Create a cursor object\n","cursor = conn.cursor()\n","\n","# Execute a query to retrieve data\n","cursor.execute(\"SELECT filename, metadata FROM metadata\")\n","\n","# Fetch all rows from the query\n","rows = cursor.fetchall()\n","\n","# Loop through the rows to get key and value\n","for row in rows:\n","    filename = row[0]  # Filename column\n","    metadata = row[1]  # Metadata column\n","    data_dict[filename] = metadata\n","\n","# Close the connection\n","\n","\n","conn.close()\n"],"metadata":{"id":"GdaSml8vjmcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nC-DmD3H8BIo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["video_path = '/content/drive/MyDrive/COPY/VOL00002/NATIVES/NATIVE00001/DEF_000268134.mp4'\n","\n","video_query = data_dict[video_path]\n","print(video_query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jrofv7cSjmZA","executionInfo":{"status":"ok","timestamp":1717449055818,"user_tz":240,"elapsed":150,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"e6c85ef2-40fc-4195-fa4d-1870651f83ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"configuration: --prefix\": \"/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\",\n","    \"size\": \"0kB time=-577014:32:22.77 bitrate=N/A speed=N/A\"\n","}\n"]}]},{"cell_type":"code","source":["from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n","from llama_index.core import VectorStoreIndex\n","\n","\n","node1 = TextNode(text=video_query)\n","\n","nodes = [node1]\n","\n","#!!! metadata title from other spreadsheet\n","\n","vector_index = VectorStoreIndex(nodes)\n","vector_index.as_query_engine()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLkcoCSqjmWO","executionInfo":{"status":"ok","timestamp":1717449074947,"user_tz":240,"elapsed":268,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"85096ea3-1e16-420a-e315-88976da2b04e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x793286056170>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["response = query_engine.query(\"what are all details related to time?\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Dlu4D-BjmTi","executionInfo":{"status":"ok","timestamp":1717449081438,"user_tz":240,"elapsed":2387,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"2f6fb6cf-d605-48b2-fafc-373b4eba33b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The input video has a duration of 00:00:33.32, starting at 0.000000 seconds with a bitrate of 2386 kb/s. The video stream has a frame rate of 29.98 fps, a time base of 30 tbr, 600 tbn, and 60 tbc. The creation time of the video is 2020-06-01T02:52:01.000000Z.\n"]}]},{"cell_type":"markdown","source":["--------------"],"metadata":{"id":"WpLSy1MM7Jqa"}},{"cell_type":"code","source":["import nest_asyncio\n","\n","nest_asyncio.apply()\n","\n","import os\n","import openai\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"key\"\n","\n","\n","from llama_index.llms.openai import OpenAI\n","from llama_index.core.schema import MetadataMode\n","\n","llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\", max_tokens=512)\n"],"metadata":{"id":"RXe50pL_uUwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from llama_index.core.extractors import (\n","    SummaryExtractor,\n","    QuestionsAnsweredExtractor,\n","    TitleExtractor,\n","    KeywordExtractor,\n","    BaseExtractor,\n",")\n","from llama_index.extractors.entity import EntityExtractor\n","from llama_index.core.node_parser import TokenTextSplitter\n","\n","text_splitter = TokenTextSplitter(\n","    separator=\" \", chunk_size=512, chunk_overlap=128\n",")\n","\n","\n","class CustomExtractor(BaseExtractor):\n","    def extract(self, nodes):\n","        metadata_list = [\n","            {\n","                \"custom\": (\n","                    node.metadata[\"document_title\"]\n","                    + \"\\n\"\n","                    + node.metadata[\"excerpt_keywords\"]\n","                )\n","            }\n","            for node in nodes\n","        ]\n","        return metadata_list\n","\n","\n","extractors = [\n","    TitleExtractor(nodes=5, llm=llm),\n","    QuestionsAnsweredExtractor(questions=3, llm=llm),\n","    # EntityExtractor(prediction_threshold=0.5),\n","    # SummaryExtractor(summaries=[\"prev\", \"self\"], llm=llm),\n","    # KeywordExtractor(keywords=10, llm=llm),\n","    # CustomExtractor()\n","]\n","\n","transformations = [text_splitter] + extractors"],"metadata":{"id":"DH3ewpC6yPkN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","api_key = 'key'  # Replace with your actual OpenAI API key\n","\n","client = OpenAI(api_key=api_key)\n","\n","completion = client.chat.completions.create(\n","  model=\"gpt-3.5-turbo\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a metadata querying assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Extract and provide all information related to time, date, year, and anything that looks like a time stamp from the given metadata: \" + metadata_output}\n","  ]\n",")\n","\n","print(completion.choices[0].message)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqNMobGs3FGy","executionInfo":{"status":"ok","timestamp":1716496362897,"user_tz":240,"elapsed":1977,"user":{"displayName":"Karyn Nakamura","userId":"07789206291232155731"}},"outputId":"ea9407f0-3f96-4877-cc65-1ac12a786eb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ChatCompletionMessage(content='The information related to time, date, and year extracted from the given metadata is as follows:\\n\\n1. Creation Time:\\n   - Video creation time: 2020-06-01T02:52:01.000000Z\\n   - Audio creation time: 2020-06-01T02:52:01.000000Z\\n\\nPlease let me know if you need more information or further assistance.', role='assistant', function_call=None, tool_calls=None)\n"]}]}]}